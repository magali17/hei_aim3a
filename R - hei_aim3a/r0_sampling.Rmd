---
title: "Additional onroad predictions"
date: "Updated `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
editor_options: 
  chunk_output_type: console
---

https://github.com/magali17/hei_aim3a

```{r setup, include=FALSE, echo=F}
#-------------r.setup-------------
knitr::opts_chunk$set(echo = FALSE,
                      warning=FALSE,
                      message=FALSE)
#knitr::opts_knit$set(root.dir = "/home/NETID/doubleda/My Documents/PhD/Year1/Fall2020/Rotation")
 
# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
    res <- suppressWarnings(
        lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
               detach, character.only=TRUE, unload=TRUE, force=TRUE))
   
}

#----------------load.libraries.pacman----
# Load pacman into memory, installing as needed
my_repo <- 'http://cran.r-project.org'
if (!require("pacman")) {install.packages("pacman", repos = my_repo)}

pacman::p_load(knitr, data.table, ggplot2, tidyverse, kableExtra, lubridate, ggpubr, tsibble, DescTools,
              parallel, future.apply, purrr,
              psych, sf, tmap, mapview #added 2/29/24
              )

dt_path <- file.path("data", "onroad", "annie", "Additional Sampling")
#source("./TRAP_rotation/code/ad_functions.R")

#save updated estimates
new_dt_pt <- file.path("data", "onroad", "annie", "v2")
if(!dir.exists(file.path(new_dt_pt, "design_samples"))){dir.create(file.path(new_dt_pt, "design_samples"), recursive = T)}



########################################################################################################
# COMMON VARIABLES
########################################################################################################
sim_n <- 30
business_hours <- c(9:17)


# --> ??
visit_med_high <- log(12)
visit_med_low <- log(4)

visit_sd. <- log(2)


########################################################################################################
# FUNCTIONS
########################################################################################################
log_normal_sample <- function(med, sd, max_value=28) {
  value <- rlnorm(1, med, sd) %>%
    round()
  # cap the max # of samples
  value <- min(value, max_value)
}



```

```{r,eval=F}
ufp_onroad_excl = readRDS(
#file.path("data", "onroad", "annie", "OnRoad Paper Code Data", "data", "All_Onroad_12.20.rds")
"/projects/rad/Transfer/Magali/hei_aim3a/R - hei_aim3a/data/onroad/annie/OnRoad Paper Code Data/data/All_Onroad_12.20.rds"
) %>% #3,769,325
  dplyr::filter(A1_flag ==0) %>% 
  dplyr::filter(road_type != "A1") %>%  #DROPPING A1s drops  395889, or 10.5% of measurements; 3,373,436
  #mutate(measurement_flag = ifelse(median_measurement>=5, ">=5", "<5")) 
  dplyr::filter(median_measurement >= 5) %>% #drops an additional 28,006 after A1s dropped; left with 3,345,430
  #mutate(median_num_flag = ifelse(num_visit>=23, ">=23", "<23"))
  dplyr::filter(num_visit >=23) %>% #additional 77,113 dropped after previous 2 filters; left with 3268317
  dplyr::filter(update_exclude_flag == 0) %>% #3268317
     mutate(date = substr(time, 1, 10),
         hour = substr(time, 12, 13),
         minute = substr(time, 15, 16), 
         second = substr(time, 18,19))

#covariates for on-road segment midpoints 
#cov_mm <- readRDS(file.path("TRAP_rotation", "data", "cov_onroad_preprocessed.rds")) 

ufp_join = ufp_onroad_excl %>%
  dplyr::select(runname, date, hour, minute, second, id, mx, my, update_exclude_flag, road_type)

all_pollutant_10s = readRDS(file = file.path(#"TRAP_rotation", "code", "Peak Identification", 
  # "data", "onroad", "annie", "OnRoad Paper Code Data", "data", 
  # "all_pollutants_10s_20220125.rds")
  "/projects/rad/Transfer/Magali/hei_aim3a/R - hei_aim3a/data/onroad/annie/OnRoad Paper Code Data/data/all_pollutants_10s_20220125.rds"
  )) %>%
  dplyr::inner_join(ufp_join, by=c("date", "hour", "minute", "second")) %>%
  dplyr::filter(update_exclude_flag == 0)

segment_locations_update = all_pollutant_10s %>%
  select(id, runname, mx, my) %>%
  distinct(id, mx, my, .keep_all=T)

# clusters based on k-means (spatial location, not time/route structure)
clusters <- readRDS(file.path("data", "onroad", "annie", "segment_clusters_updated.rds")) %>%
  select(id=location, cluster, cluster2)

clusters_update = all_pollutant_10s %>% 
  inner_join(segment_locations_update) %>% 
  select(id, runname, time, mx, my) %>% 
  mutate(route = substr(runname, 12, 14)) %>% 
  arrange(time) %>% 
  select(id, route) %>% 
  distinct() %>% 
  group_by(route) %>% 
  mutate(cluster = ceiling(row_number()/100)) %>% 
  mutate(cluster_update = paste0(route, "-", cluster))

cluster_naming = clusters_update %>% 
  ungroup() %>% 
  select(cluster_update) %>% 
  distinct() %>% 
  mutate(cluster_final = row_number())

clusters_final = clusters_update %>% 
  as.data.frame() %>% 
  ungroup() %>% 
  select(id, cluster_update) %>% 
  left_join(cluster_naming) %>% 
  select(id, cluster_final) %>% 
  rename(cluster3=cluster_final) %>%
  
  # add new, spatial clusters
  # right join bc updated clusters have 9 more segments
  right_join(clusters)

#saveRDS(clusters_final, file = file.path("TRAP_rotation", "data", "segment_clusters.rds"))

# --> add other clusters

   
  
```



```{r,eval=F}
library(lubridate)

all_pollutant_10s_complete = all_pollutant_10s %>%
  #rename(site_id = site_id.x) %>% 
  dplyr::filter(site_id == "onroad") %>%  #385697
  dplyr::filter(!is.na(no2) & !is.na(pmdisc_number) & !is.na(bc_ngm3) &
         !is.na(ufp_pt_screen_ct_cm3) & !is.na(co2))  %>% 
  dplyr::select(-c(no2_flag, no2_instrument, site))#335987

all_pollutant_10s_complete = all_pollutant_10s_complete %>%
  mutate(ufp_pr_dif = ufp_pt_noscreen_ct_cm3 - ufp_pt_screen_ct_cm3) %>% 
  mutate(ufp_pr_dif = ifelse(ufp_pr_dif < 0, 1000, ufp_pr_dif)) %>%
  mutate(pm_size_bins = ifelse(pmdisc_size <36, 0, 1)) 


winsorize_pol = function(var, min=0.05, max=0.95) {
  Winsorize(var, minval=quantile(var, min), maxval=quantile(var, max), na.rm=T)
}

all_pollutant_10s_winsorize_site = all_pollutant_10s_complete %>% 
  dplyr::filter(!(id %in% c(6796, 534, 3064, 867))) %>% #roosevelt garage
  group_by(id, mx, my) %>%
  mutate(ufp_noscreen_winsorize = winsorize_pol(ufp_pt_noscreen_ct_cm3), 
         ufp_screen_winsorize = winsorize_pol(ufp_pt_screen_ct_cm3),
         disc_num_winsorize = winsorize_pol(pmdisc_number),
         bc_winsorize = winsorize_pol(bc_ngm3),
         ufp_pr_dif_winsorize = winsorize_pol(ufp_pr_dif),
         pmdisc_size_winsorize = winsorize_pol(pmdisc_size),
         no2_winsorize = winsorize_pol(no2),
         co2_winsorize = winsorize_pol(co2)) 

pca.vars.winsorize =c("ufp_noscreen_winsorize", "ufp_screen_winsorize", "ufp_pr_dif_winsorize", 
                      "disc_num_winsorize",  "no2_winsorize",
                      "bc_winsorize", "co2_winsorize")

pca.pol.winsorize <- principal(scale(all_pollutant_10s_winsorize_site[pca.vars.winsorize]),
                               nfactors=3, rotate="Varimax",covar = F, scores=T)

pca.pol.winsall = predict(pca.pol.winsorize, all_pollutant_10s_winsorize_site[pca.vars.winsorize])

pca.pol.winsall = as.data.frame(pca.pol.winsall)


zero.vals<-predict(pca.pol.winsorize,c(0,0,0,0,0,0,0),all_pollutant_10s_winsorize_site[pca.vars.winsorize])

adj.scores<-pca.pol.winsall
adj.scores[,1]<-pca.pol.winsall[,1]-zero.vals[1]
adj.scores[,2]<-pca.pol.winsall[,2]-zero.vals[2]
adj.scores[,3]<-pca.pol.winsall[,3]-zero.vals[3]
#adj.scores[,4]<-pca.pol.winsall[,4]-zero.vals[4]

adj.scores=as.matrix(adj.scores)

pnc_model = lm(all_pollutant_10s_winsorize_site$ufp_noscreen_winsorize ~ adj.scores) 
summary(pnc_model)

#coef(lm(all_pollutant_10s_winsorize_site$ufp_noscreen_winsorize ~ adj.scores))[-1]*abs(zero.vals)


#predict pnc concentrations based on fitted model; and then you have an estimate of how much is derived from the scores and from the residuals 

adj.pc.scores = as.data.frame(adj.scores)

wins_pca_fit = all_pollutant_10s_winsorize_site %>%
  dplyr::bind_cols(pnc_model$fitted.values, pnc_model$residuals) %>%
  dplyr::rename(pnc_preds = `...33`,
         pnc_resids = `...34`) %>% 
  cbind(pca.pol.winsall) %>% 
  dplyr::rename(PC1 = RC1, 
         PC2 = RC2, 
         PC3 = RC3) %>%  
         #PC4 = RC3) %>%
  cbind(adj.pc.scores) %>%
  dplyr::rename(PC1_adj = RC1, 
         PC2_adj = RC2, 
         PC3_adj = RC3) %>%  
         #PC4_adj = RC4) %>%
  mutate(intercept = coef(pnc_model)[1],
         pnc_pc1 = PC1_adj*coef(pnc_model)[2],
         pnc_pc2 = PC2_adj*coef(pnc_model)[3],
         pnc_pc3 = PC3_adj*coef(pnc_model)[4]) 

mute_pcs_threshset = function(df, thresh, factor) {
  wins_pca_ts = df %>%
    dplyr::distinct(time, .keep_all = TRUE) %>% 
    tsibble::as_tsibble(index = time) %>%
    dplyr::arrange(time) %>%
    mutate(below_med_pc2 = ifelse(PC2_adj < median(PC2_adj, na.rm=T), 1, 0), 
           below_med_pc3 = ifelse(PC3_adj < median(PC3_adj, na.rm=T), 1, 0)) 

  below_pc2 = wins_pca_ts %>% dplyr::filter(below_med_pc2==1)
  below_pc3 = wins_pca_ts %>% dplyr::filter(below_med_pc3==1)

  sd_below_med_pc2 = sd(below_pc2$PC2_adj)
  sd_below_med_pc3 = sd(below_pc3$PC3_adj)

  wins_pca_ts_sd_flag_pnc = wins_pca_ts %>%
    mutate(sd_flag_pc2 = ifelse(PC2_adj > ((3*sd_below_med_pc2) + lag(PC2_adj)), 1, 0), 
           sd_flag_pc2 = ifelse(sd_flag_pc2 ==1 & (PC2_adj > quantile(PC2_adj, thresh)), 1, 0), 
           pc2_90_thresh_flag = ifelse(PC2_adj > quantile(PC2_adj, thresh), 1, 0), 
           #pc2_90_thresh_flag = ifelse(lag(pc2_90_thresh_flag) == 1 & 
           #                             lead(pc2_90_thresh_flag) == 1, 1, pc2_90_thresh_flag),
           pc2_adj_flag = ifelse(pc2_90_thresh_flag == 1 | sd_flag_pc2 == 1, 1, 0), 
           pc2_adj_thresh = ifelse(pc2_adj_flag == 1, quantile(PC2_adj, thresh), PC2_adj),
           sd_flag_pc3 = ifelse(PC3_adj > ((3*sd_below_med_pc3) + lag(PC3_adj)), 1, 0), 
           sd_flag_pc3 = ifelse(sd_flag_pc3 ==1 & (PC3_adj > quantile(PC3_adj, thresh)), 1, 0),
           pc3_90_thresh_flag = ifelse(PC3_adj > quantile(PC3_adj, thresh), 1, 0), 
           #pc3_90_thresh_flag = ifelse(lag(pc3_90_thresh_flag) == 1 & 
          #                             lead(pc3_90_thresh_flag) == 1, 1, pc3_90_thresh_flag),
           pc3_adj_flag = ifelse(pc3_90_thresh_flag == 1 | sd_flag_pc3 == 1, 1, 0),
           pc3_adj_thresh = ifelse(pc3_adj_flag == 1, quantile(PC3_adj, thresh), PC3_adj),
           pnc_resid_wins = Winsorize(pnc_resids),
           pc1_unadj = PC1_adj, 
           pc2_unadj = pc2_adj_thresh,
           pc3_unadj = pc3_adj_thresh,
           pnc_pc1_adj = pc1_unadj*coef(pnc_model)[2],
           pnc_pc2_adj = pc2_unadj*(factor*coef(pnc_model)[3]),
           pnc_pc3_adj = pc3_unadj*(factor*coef(pnc_model)[4])) %>%
    mutate(pnc_pred_adj_all = pnc_resids + intercept + pnc_pc1_adj + pnc_pc2_adj + 
             pnc_pc3_adj)#,
           #pnc_pred_adj_all = ifelse(pnc_pred_adj_all < quantile(ufp_noscreen_winsorize, 0.05),
          #                           ufp_noscreen_winsorize, pnc_pred_adj_all))
  return(wins_pca_ts_sd_flag_pnc)
}

```


```{r,eval=F}
primary_adj_pnc_update = mute_pcs_threshset(wins_pca_fit, thresh = 0.75, factor=0.99) %>% 
  mutate(dow = wday(date, label=TRUE, abbr=FALSE)) %>% 
  mutate(dow2 = ifelse(dow %in% c("Saturday", "Sunday"), "weekend", "weekday")) %>% 
  mutate(pnc_pred_adj_all = ifelse(pnc_pred_adj_all<0, ufp_noscreen_winsorize, pnc_pred_adj_all))

primary_adj_pnc_update = data.frame(primary_adj_pnc_update)

get_median_adj <- function(output) {
  get_median = output %>%
    ungroup() %>% 
    group_by(id, runname, date, hour) %>%
    summarise(median_value = median(pnc_pred_adj_all, na.rm=T))
  return(get_median)
}

primary_adj_pnc_med_update = get_median_adj(primary_adj_pnc_update) %>% 
  group_by(id) %>% 
  mutate(visit_num = n())


primary_unadj_pnc = all_pollutant_10s_winsorize_site %>% 
  mutate(dow = wday(date, label=TRUE, abbr=FALSE)) %>% 
  mutate(dow2 = ifelse(dow %in% c("Saturday", "Sunday"), "weekend", "weekday"))

primary_unadj_pnc = data.frame(primary_unadj_pnc)

get_median_adj <- function(output) {
  get_median = output %>%
    group_by(id, runname, date, dow, dow2, hour) %>%
    summarise(median_value = median(ufp_noscreen_winsorize, na.rm=T))
  return(get_median)
}

primary_unadj_pnc_med = get_median_adj(primary_unadj_pnc) %>% 
  group_by(id) %>% 
  mutate(visit_num = n())

saveRDS(primary_adj_pnc_med_update, file = file.path("TRAP_rotation", "data", "AdjPNCMedian.rds"))

saveRDS(primary_unadj_pnc_med, file = file.path("TRAP_rotation", "data", "UnadjPNCMedian.rds"))



```

```{r}
set.seed(21)

cov_mm = readRDS(file=file.path("/projects/rad/Transfer/Magali/hei_aim3a/R - hei_aim3a/data/onroad/annie/OnRoad Paper Code Data/data/", "cov_onroad_preprocessed.rds")) %>% 
  select(id, latitude, longitude)

#Adjusted PNC Medians 
adj_pnc_med = readRDS(file = file.path("data", "onroad", "annie", "Additional Sampling", "AdjPNCMedian.rds")) %>% 
  mutate(dow = lubridate::wday(date, label=TRUE, abbr=FALSE)) %>% 
  mutate(dow2 = ifelse(dow %in% c("Saturday", "Sunday"), "weekend", "weekday"))

#Unadjusted PNC Medians
unadj_pnc_med = readRDS(file = file.path("data", "onroad", "annie", "Additional Sampling", "UnadjPNCMedian.rds")) %>% 
  group_by(id) %>% 
  mutate(visit_num = n())

segment_clusters <- readRDS(file.path("data", "onroad", "annie", "segment_clusters_updated.rds")) %>%
  select(id=location, contains("cluster")) 

segment_clusters_l <- segment_clusters %>%
  pivot_longer(cols = contains("cluster"), names_to = "cluster_type", values_to = "cluster_value")
   
road_type <- readRDS(file.path("data", "onroad", "annie", "OnRoad Paper Code Data", "data", "All_Onroad_12.20.rds")) %>%
  distinct(id, road_type) %>%
  filter(road_type != "A!")

```

Site annual averages vs variability  

```{r}
unadj_pnc_summary = unadj_pnc_med %>% 
  group_by(id) %>% 
  summarise(annual_avg = mean(median_value, na.rm=T), 
            sd = sd(median_value, na.rm=T))

adj_pnc_summary = adj_pnc_med %>% 
  group_by(id) %>% 
  summarise(annual_avg = mean(median_value, na.rm=T), 
            sd = sd(median_value, na.rm=T))

unadj_pnc_summary_map = unadj_pnc_summary %>% 
  inner_join(segment_clusters) %>% 
  left_join(cov_mm) %>%
  
  pivot_longer(cols = contains("cluster"), names_to = "cluster_type", values_to = "cluster_value") %>%
  
  mutate(cluster_value = factor(cluster_value))

# pts = st_as_sf(unadj_pnc_summary_map, coords = c("longitude","latitude"),  crs = 4326)
# 
# tm_shape(pts) +
#   tm_dots(col = "cluster")
# 
# # --> adds background map; can zoom in
# mapview(pts, zcol="cluster")


#rank order clusters by average annual average OR average SD; then rank order lognormal dist and assign that way
cluster_rank = unadj_pnc_summary_map %>%
  group_by(cluster_type, cluster_value) %>% 
  summarise(avg_ann_avg = mean(annual_avg, na.rm=T),
            avg_sd = mean(sd, na.rm=T)) %>% 
  arrange(desc(avg_ann_avg)) %>% 
  mutate(ann_avg_rank = row_number()) %>% 
  arrange(desc(avg_sd)) %>% 
  mutate(sd_avg_rank = row_number())

##cluster road type 
cluster_road_type = segment_clusters_l %>% 
  left_join(road_type) %>% 
  group_by(cluster_type, cluster_value) %>% 
  mutate(Total = n()) %>% 
  ungroup() %>% 
  group_by(cluster_type, cluster_value, road_type, Total) %>% 
  summarise(Freq = n()) %>% 
  mutate(percent = Freq/Total*100) %>% 
  pivot_wider(id_cols = c(cluster_type, cluster_value), 
              names_from = "road_type", values_from = "percent") 

assign_rank1 = cluster_road_type %>% 
  filter(!is.na(A2)) %>% 
  group_by(cluster_type, cluster_value) %>%
  arrange(desc(A2)) %>% 
  group_by(cluster_type) %>%
  mutate(rank = row_number())# %>% 
  select(cluster_type, cluster_value, rank)
 
assign_rank2 = cluster_road_type %>% 
  filter(is.na(A2)) %>% 
  group_by(cluster_type, cluster_value) %>%
  arrange(desc(A3)) %>%  
  ungroup() %>% 
  group_by(cluster_type) %>%
  mutate(rank = row_number()) %>% 
  mutate(rank = rank+20) %>% 
  select(cluster_type, cluster_value, rank)

cluster_road_type_rank = assign_rank1 %>% 
  bind_rows(assign_rank2)
```


## Design 1: Sample 4 or 12 visits per site 

# --> WHERE ARE THE 4 VISITS??

```{r}
visits=12

one_sample_avg_balanced = function(df) {
  one_sample = df %>%
    group_by(id) %>% 
    slice_sample(n=visits, replace=T) %>% 
    summarise(annual_mean = mean(median_value, na.rm=T))
  return(one_sample)
}

balanced_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_balanced(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      design = "balanced",
      visits = "12 visits",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame()

balanced_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_balanced(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      design = "balanced",
      visits = "12 visits",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame()


balanced_design = rbind(balanced_unadj, balanced_adj)

saveRDS(balanced_design, file = file.path(new_dt_pt, "design_samples", "PNC_annavg_balanced_12vis.rds"))
```


## Unbalanced design 1  
Sample all segments, where the visits sampled is median of 12 (or 4), sampled from lognormal distribution 

```{r}
set.seed(21)

#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#GM = median = 6; geometric SD = 2
# visit_nums = rlnorm(63, log(4), log(2))
# visit_nums = round(visit_nums, digits=0)

# med=log(12)
# sd=(2)
# max_value=28


# df = unadj_pnc_med
# visit_med=visit_med.
# visit_sd=visit_sd.

one_sample_avg_unb_random = function(df, visit_med, visit_sd, get_annual_avg = T) {
  one_sample = df%>%
    group_by(id) %>% 
    mutate(#weight = sample(visit_nums, 1)
           weight = log_normal_sample(med=visit_med, sd=visit_sd)
           ) %>% 
    group_by(id, weight) %>%  
    nest() %>%
    ungroup() %>%
    mutate(samp = map2(data, weight, sample_n, replace=T)) %>%
    select(-data) %>%
    unnest(samp) %>%
    group_by(id) %>%
    mutate(visits = n()) 
  
  #calculate annual average
  if(get_annual_avg == TRUE) {
    one_sample <- one_sample %>%
      summarise(annual_mean = mean(median_value, na.rm=T))
  }
  
  return(one_sample)
}


unbal_ran_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_random(unadj_pnc_med, visit_med=visit_med_high, visit_sd=visit_sd.), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      design = "unbalanced", 
      visits = "median 12",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame()

unbal_ran_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_random(adj_pnc_med, visit_med=visit_med_high, visit_sd=visit_sd.), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      design = "unbalanced", 
      visits = "median 12",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame()


unbal_ran_design = rbind(unbal_ran_unadj, unbal_ran_adj)

saveRDS(unbal_ran_design, file = file.path(new_dt_pt, "design_samples", "PNC_annavg_unbal_12.rds"))
```


#--> START HERE

## Design 2: Business hours sampling: 4 or 12 visits 


```{r}
visits=12

#try for 1 campaign
# one_sample_avg = unadj_pnc_med %>%
#   filter(dow2 == "weekday", hour %in% business_hours) %>% 
#   group_by(id) %>% 
#   slice_sample(n=visits, replace=T) %>% 
#   summarise(annual_mean = mean(median_value, na.rm=T))

one_sample_avg_bh = function(df) {
  one_sample = df %>%
    filter(dow2 == "weekday", hour %in% business_hours) %>% 
    group_by(id) %>% 
    slice_sample(n=visits, replace=T) %>% 
    summarise(annual_mean = mean(median_value, na.rm=T))
  return(one_sample)
}

bh_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_bh(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "business hours",
      design = "unbalanced", 
      visits = "12 visits",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame()

bh_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_bh(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "business hours",
      design = "unbalanced", 
      visits = "12 visits",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame()


bh_design = rbind(bh_unadj, bh_adj)

saveRDS(bh_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_bh_12.rds"))


```


## Unbalanced design 1: business hours   
Sample all segments, where the visits sampled is median of 12 (or 4), sampled from lognormal distribution 

```{r}
set.seed(21)
business_hours <- c(9:17)

#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6
#GM = median = 6; geometric SD = 2
visit_nums = rlnorm(50, log(12), log(2))
visit_nums = round(visit_nums, digits=0)


one_sample_avg_random_bh = function(df) {
  one_sample = df %>% 
    filter(dow2 == "weekday", hour %in% business_hours) %>% 
    group_by(id) %>% 
    mutate(weight = sample(visit_nums, 1)) %>% 
    group_by(id, weight) %>%
    nest() %>%
    ungroup() %>%
    mutate(samp = map2(data, weight, sample_n, replace=T)) %>%
    select(-data) %>%
    unnest(samp) %>%
    group_by(id) %>%
    mutate(visits = n()) %>%
      #calculate annual average
    summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample)
}


unbal_ran_bh_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_random_bh(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "business hours",
      design = "unbalanced", 
      visits = "median 12", 
      adjusted = "unadjusted"
    ) %>%
    as.data.frame()

unbal_ran_bh_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_random_bh(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "business hours",
      design = "unbalanced", 
      visits = "median 12", 
      adjusted = "unadjusted"
    ) %>%
    as.data.frame()


unbal_ran_bh_design = rbind(unbal_ran_bh_unadj, unbal_ran_bh_adj)

saveRDS(unbal_ran_bh_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbal_bh_12.rds"))
```


```{r}
#save all non-spatial designs on trap/transfer 

save_dir = "//projects/trap/transfer/annie/OnroadAnnAvgs"

saveRDS(PNC_nonspatial, file=file.path(save_dir, "PNC_nonspatial_annavgs.rds"))

```



# Pre-defined site clustering: all hours   
Randomly pick number of visits per CLUSTER from the lognormal distribution  
Pick drive days to apply to the entire cluster.

```{r}
clusters = readRDS(file = file.path("TRAP_rotation", "data", "segment_clusters.rds")) %>% 
  select(id, cluster)  

set.seed(21)
#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#GM = median = 6; geometric SD = 2
visit_nums = rlnorm(63, log(4), log(2))
visit_nums = round(visit_nums, digits=0)

one_sample_avg_unb_cluster = function(df) {
  one_sample = df %>%
    left_join(clusters) %>% 
    group_by(cluster) %>% 
    mutate(weight = sample(visit_nums, 1)) 
 
   sample_days = one_sample %>% 
     select(date, cluster, weight) %>% 
     distinct() %>% 
     group_by(cluster, weight) %>% 
     nest() %>% 
     mutate(samp = map2(data, weight, sample_n, replace = T)) %>% 
     select(-data) %>% 
     unnest(samp)
   
   one_sample_final = one_sample %>% 
     ungroup() %>% 
     inner_join(sample_days, by=c("date", "cluster", "weight")) %>% 
     group_by(id) %>% 
     summarise(annual_mean = mean(median_value, na.rm=T)) %>% 
     ungroup() 
  
  return(one_sample_final)
}



unbal_cluster_unadj <- future_replicate(n = sim_n,
                           #future.label = TRUE,
                           simplify = F,
                           expr = one_sample_avg_unb_cluster(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    #group_by(id) %>%
    mutate(
      #campaign = row_number(),
      version = "all hours",
      design = "clustered", 
      visits = "median 4 visits",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


  
unbal_cluster_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_cluster(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    #group_by(id) %>%
    mutate(
      #campaign = row_number(),
      version = "all hours",
      design = "clustered", 
      visits = "median 4 visits",
      adjusted = "adjusted"
    ) %>%
    as.data.frame() %>%
    mutate(dif = id - lag(id)) %>%
    mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


unbal_cluster_design = rbind(unbal_cluster_unadj, unbal_cluster_adj) %>% 
  select(id, annual_mean, campaign, version, design, visits, adjusted)

saveRDS(unbal_cluster_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbal_cluster.rds"))
```

# Pre-defined site clustering: business hours   
Randomly pick number of visits per CLUSTER from the lognormal distribution  
Pick drive days to apply to the entire cluster.

```{r}
clusters = readRDS(file = file.path("TRAP_rotation", "data", "segment_clusters.rds")) %>% 
  select(id, cluster)  

set.seed(21)
business_hours <- c(9:17)
#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#GM = median = 6; geometric SD = 2
#visit_nums = rlnorm(50, log(4), log(2))
#visit_nums = round(visit_nums, digits=0)

one_sample_avg_unb_cluster_bh = function(df) {
  one_sample = df %>%
    filter(dow2 == "weekday", hour %in% business_hours) %>%
    left_join(clusters) %>% 
    group_by(cluster) %>% 
    mutate(weight = sample(visit_nums, 1)) 
 
   sample_days = one_sample %>% 
     select(date, cluster, weight) %>% 
     distinct() %>% 
     group_by(cluster, weight) %>% 
     nest() %>% 
     mutate(samp = map2(data, weight, sample_n, replace = T)) %>% 
     select(-data) %>% 
     unnest(samp)
   
   one_sample_final = one_sample %>% 
     ungroup() %>% 
     inner_join(sample_days, by=c("date", "cluster", "weight")) %>% 
     group_by(id) %>% 
     summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample_final)
}


unbal_cluster_bh_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_cluster_bh(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    #group_by(id) %>%
    mutate(
      #campaign = row_number(),
      version = "business hours",
      design = "clustered", 
      visits = "median 4 visits",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))

unbal_cluster_bh_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_cluster_bh(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    #group_by(id) %>%
    mutate(
      #campaign = row_number(),
      version = "business hours",
      design = "clustered", 
      visits = "median 4 visits",
      adjusted = "adjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


unbal_cluster_bh_design = rbind(unbal_cluster_bh_unadj, unbal_cluster_bh_adj) %>% 
  select(id, annual_mean, campaign, version, design, visits, adjusted)

saveRDS(unbal_cluster_bh_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbal_cluster_bh.rds"))
```


# Spatial structure: Model 1  
Using the pre-defined site clusters, sample from the lognormal distribution to create spatial structure in the #visits per site, using the same drive day algorithm.  

Model 1: High number of visits along chunks/routes where we expect a lot of exposure contrast; fewer where we don't. Assign clusters with high annual averages and high SD to higher number of visits. 

```{r}
clusters = readRDS(file = file.path("TRAP_rotation", "data", "segment_clusters.rds")) %>% 
  select(id, cluster)

set.seed(21)
#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#GM = median = 6; geometric SD = 2
#visit_nums = rlnorm(56, log(4), log(2))
#visit_nums = round(visit_nums, digits=0)

visit_nums_rank = as.data.frame(visit_nums) %>% 
  arrange(desc(visit_nums)) %>% 
  mutate(rank = row_number())

cluster_rank_select = cluster_rank %>% 
  select(cluster, ann_avg_rank) %>% 
  left_join(visit_nums_rank, by=c("ann_avg_rank" = "rank"))
 

one_sample_avg_unb_spatial = function(df) {
  
  one_sample = df %>%
    left_join(clusters) %>% 
    left_join(cluster_rank_select) %>% 
    ungroup()
 
   sample_days = one_sample %>% 
     select(date, cluster, visit_nums) %>% 
     distinct() %>% 
     filter(!is.na(cluster)) %>% 
     group_by(cluster, visit_nums) %>% 
     nest() %>% 
     mutate(samp = map2(data, visit_nums, sample_n, replace = T)) %>% 
     select(-data) %>% 
     unnest(samp)
   
   one_sample_final = one_sample %>% 
     ungroup() %>% 
     inner_join(sample_days, by=c("date", "cluster", "visit_nums")) %>% 
     group_by(id) %>% 
     summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample_final)
}


unbal_spatial_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    #group_by(id) %>%
    mutate(
      #campaign = row_number(),
      version = "all hours",
      design = "sensible spatial", 
      visits = "median 4",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


unbal_spatial_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    mutate(
      #campaign = row_number(),
      version = "all hours",
      design = "sensible spatial", 
      visits = "median 4",
      adjusted = "adjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


unbal_spatial_design = rbind(unbal_spatial_unadj, unbal_spatial_adj) %>% 
  select(id, annual_mean, campaign, version, design, visits, adjusted)

saveRDS(unbal_spatial_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbal_spatial.rds"))

```


# Spatial structure: Model 1, business hours   
Using the pre-defined site clusters, sample from the lognormal distribution to create spatial structure in the #visits per site, using the same drive day algorithm.  

Model 1: High number of visits along chunks/routes where we expect a lot of exposure contrast; fewer where we don't. Assign clusters (or full routes?) with high annual averages and high SD to higher number of visits. 

```{r}
clusters = readRDS(file = file.path("TRAP_rotation", "data", "segment_clusters.rds")) %>% 
  select(id, cluster)


set.seed(21)
business_hours <- c(9:17)
#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#visit_nums = rlnorm(56, log(4), log(2))
#visit_nums = round(visit_nums, digits=0)

#visit_nums_rank = as.data.frame(visit_nums) %>% 
#  arrange(desc(visit_nums)) %>% 
#  mutate(rank = row_number())

cluster_rank_select = cluster_rank %>% 
  select(cluster, ann_avg_rank) %>% 
  left_join(visit_nums_rank, by=c("ann_avg_rank" = "rank"))
 

one_sample_avg_unb_spatial_bh = function(df) {
  
  one_sample = df %>%
    filter(dow2 == "weekday", hour %in% business_hours) %>%
    left_join(clusters) %>% 
    left_join(cluster_rank_select) %>% 
    ungroup()
 
   sample_days = one_sample %>% 
     select(date, cluster, visit_nums) %>% 
     distinct() %>% 
     filter(!is.na(cluster)) %>% 
     group_by(cluster, visit_nums) %>% 
     nest() %>% 
     mutate(samp = map2(data, visit_nums, sample_n, replace = T)) %>% 
     select(-data) %>% 
     unnest(samp)
   
   one_sample_final = one_sample %>% 
     ungroup() %>% 
     inner_join(sample_days, by=c("date", "cluster", "visit_nums")) %>% 
     group_by(id) %>% 
     summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample_final)
}


unbal_spatial_bh_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial_bh(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    mutate(
      #campaign = row_number(),
      version = "business hours",
      design = "sensible spatial", 
      visits = "median 4",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))

unbal_spatial_bh_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial_bh(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    mutate(
      #campaign = row_number(),
      version = "business hours",
      design = "sensible spatial", 
      visits = "median 4",
      adjusted = "adjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


unbal_spatial_design_bh = rbind(unbal_spatial_bh_unadj, unbal_spatial_bh_adj) %>% 
  select(id, annual_mean, campaign, version, design, visits, adjusted)

saveRDS(unbal_spatial_design_bh, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbal_spatial_bh.rds"))

```


# Spatial structure: Model 2  
Using the pre-defined site clusters, sample from the lognormal distribution to create spatial structure in the #visits per site, using the same drive day algorithm.  

Model 2: High number of visits along chunks/routes where we expect a lot of exposure contrast; fewer where we don't. Assign clusters  with high annual averages and high SD to LOWER number of visits. 

```{r}
clusters = readRDS(file = file.path("TRAP_rotation", "data", "segment_clusters.rds")) %>% 
  select(id, cluster)

set.seed(21)
#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#GM = median = 6; geometric SD = 2
visit_nums = rlnorm(63, log(4), log(2))
visit_nums = round(visit_nums, digits=0)

visit_nums_rank = as.data.frame(visit_nums) %>% 
  arrange(visit_nums) %>% 
  mutate(rank = row_number())

cluster_rank_select = cluster_rank %>% 
  select(cluster, ann_avg_rank) %>% 
  left_join(visit_nums_rank, by=c("ann_avg_rank" = "rank"))

one_sample_avg_unb_spatial2 = function(df) {
  
  one_sample = df %>%
    left_join(clusters) %>% 
    left_join(cluster_rank_select) %>% 
    ungroup()
 
   sample_days = one_sample %>% 
     select(date, cluster, visit_nums) %>% 
     distinct() %>% 
     filter(!is.na(cluster)) %>% 
     group_by(cluster, visit_nums) %>% 
     nest() %>% 
     mutate(samp = map2(data, visit_nums, sample_n, replace = T)) %>% 
     select(-data) %>% 
     unnest(samp)
   
   one_sample_final = one_sample %>% 
     ungroup() %>% 
     inner_join(sample_days, by=c("date", "cluster", "visit_nums")) %>% 
     group_by(id) %>% 
     summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample_final)
}


unbal_spatial2_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial2(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
  mutate(
      #campaign = row_number(),
      version = "all hours",
      design = "unsensible spatial", 
      visits = "median 4",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))

unbal_spatial2_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial2(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    mutate(
      #campaign = row_number(),
      version = "all hours",
      design = "unsensible spatial", 
      visits = "median 4",
      adjusted = "adjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


unbal_spatial2_design = rbind(unbal_spatial2_unadj, unbal_spatial2_adj) %>% 
  select(id, annual_mean, campaign, version, design, visits, adjusted)

saveRDS(unbal_spatial2_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbal_spatial2.rds"))


```


# Spatial structure: Model 2, business hours  
Using the pre-defined site clusters, sample from the lognormal distribution to create spatial structure in the #visits per site, using the same drive day algorithm.  

Model 2: High number of visits along chunks/routes where we expect a lot of exposure contrast; fewer where we don't. Assign clusters  with high annual averages and high SD to LOWER number of visits. 

```{r}
clusters = readRDS(file = file.path("TRAP_rotation", "data", "segment_clusters.rds")) %>% 
  select(id, cluster)

set.seed(21)
business_hours <- c(9:17)
#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#GM = median = 6; geometric SD = 2
#visit_nums = rlnorm(56, log(4), log(2))
#visit_nums = round(visit_nums, digits=0)

visit_nums_rank = as.data.frame(visit_nums) %>% 
  arrange(visit_nums) %>% 
  mutate(rank = row_number())

cluster_rank_select = cluster_rank %>% 
  select(cluster, ann_avg_rank) %>% 
  left_join(visit_nums_rank, by=c("ann_avg_rank" = "rank"))

one_sample_avg_unb_spatial2_bh = function(df) {
  
  one_sample = df %>%
    filter(dow2 == "weekday", hour %in% business_hours) %>%
    left_join(clusters) %>% 
    left_join(cluster_rank_select) %>% 
    ungroup()
 
   sample_days = one_sample %>% 
     select(date, cluster, visit_nums) %>% 
     distinct() %>% 
     filter(!is.na(cluster)) %>% 
     group_by(cluster, visit_nums) %>% 
     nest() %>% 
     mutate(samp = map2(data, visit_nums, sample_n, replace = T)) %>% 
     select(-data) %>% 
     unnest(samp)
   
   one_sample_final = one_sample %>% 
     ungroup() %>% 
     inner_join(sample_days, by=c("date", "cluster", "visit_nums")) %>% 
     group_by(id) %>% 
     summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample_final)
}


unbal_spatial2_bh_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial2_bh(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    mutate(
      #campaign = row_number(),
      version = "business hours",
      design = "unsensible spatial", 
      visits = "median 4",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))

unbal_spatial2_bh_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial2_bh(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    mutate(
      #campaign = row_number(),
      version = "business hours",
      design = "unsensible spatial", 
      visits = "median 4",
      adjusted = "adjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


unbal_spatial2_bh_design = rbind(unbal_spatial2_bh_unadj, unbal_spatial2_bh_adj) %>% 
  select(id, annual_mean, campaign, version, design, visits, adjusted)

saveRDS(unbal_spatial2_bh_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbal_spatial2_bh.rds"))


```

## Spatial Structure, Model 3: Sample by road type  

Classify clusters by dominant road type and rank order by clusters with highest # of A2s, then A3s, then A4s. Assign lognormal distribution of vistis by this order.  

```{r}

clusters = readRDS(file = file.path("TRAP_rotation", "data", "segment_clusters.rds")) %>% 
  select(id, cluster)

set.seed(21)
#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#GM = median = 6; geometric SD = 2
#visit_nums = rlnorm(56, log(4), log(2))
#visit_nums = round(visit_nums, digits=0)

visit_nums_rank = as.data.frame(visit_nums) %>% 
  arrange(desc(visit_nums)) %>% 
  mutate(rank = row_number())

cluster_road_rank_select = cluster_road_type_rank %>% 
  left_join(visit_nums_rank)

one_sample_avg_unb_spatial_road = function(df) {
  
  one_sample = df %>%
    left_join(clusters) %>% 
    left_join(cluster_road_rank_select) %>% 
    ungroup()
 
   sample_days = one_sample %>% 
     select(date, cluster, visit_nums) %>% 
     distinct() %>% 
     filter(!is.na(cluster)) %>% 
     group_by(cluster, visit_nums) %>% 
     nest() %>% 
     mutate(samp = map2(data, visit_nums, sample_n, replace = T)) %>% 
     select(-data) %>% 
     unnest(samp)
   
   one_sample_final = one_sample %>% 
     ungroup() %>% 
     inner_join(sample_days, by=c("date", "cluster", "visit_nums")) %>% 
     group_by(id) %>% 
     summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample_final)
}


unbal_spatial_road_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial_road(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
     mutate(
      #campaign = row_number(),
      version = "all hours",
      design = "road type", 
      visits = "median 4",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))

unbal_spatial_road_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial_road(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
     mutate(
      #campaign = row_number(),
      version = "all hours",
      design = "road type", 
      visits = "median 4",
      adjusted = "adjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


unbal_spatial_road_design = rbind(unbal_spatial_road_unadj, unbal_spatial_road_adj) %>% 
  select(id, annual_mean, campaign, version, design, visits, adjusted)

saveRDS(unbal_spatial_road_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbal_spatial_road.rds"))
```

## Spatial Structure, Model 3: Sample by road type, Business hours  

Classify clusters by dominant road type and rank order by clusters with highest # of A2s, then A3s, then A4s. Assign lognormal distribution of vistis by this order.  

```{r}

clusters = readRDS(file = file.path("TRAP_rotation", "data", "segment_clusters.rds")) %>% 
  select(id, cluster)

set.seed(21)
#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#GM = median = 6; geometric SD = 2
#visit_nums = rlnorm(56, log(4), log(2))
#visit_nums = round(visit_nums, digits=0)

visit_nums_rank = as.data.frame(visit_nums) %>% 
  arrange(desc(visit_nums)) %>% 
  mutate(rank = row_number())

cluster_road_rank_select = cluster_road_type_rank %>% 
  left_join(visit_nums_rank)

one_sample_avg_unb_spatial_road_bh = function(df) {
  
  one_sample = df %>% 
    filter(dow2 == "weekday", hour %in% business_hours) %>%
    left_join(clusters) %>% 
    left_join(cluster_road_rank_select) %>% 
    ungroup()
 
   sample_days = one_sample %>% 
     select(date, cluster, visit_nums) %>% 
     distinct() %>% 
     filter(!is.na(cluster)) %>% 
     group_by(cluster, visit_nums) %>% 
     nest() %>% 
     mutate(samp = map2(data, visit_nums, sample_n, replace = T)) %>% 
     select(-data) %>% 
     unnest(samp)
   
   one_sample_final = one_sample %>% 
     ungroup() %>% 
     inner_join(sample_days, by=c("date", "cluster", "visit_nums")) %>% 
     group_by(id) %>% 
     summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample_final)
}


unbal_spatial_road_bh_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial_road_bh(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    mutate(
      #campaign = row_number(),
      version = "business hours",
      design = "road type", 
      visits = "median 4",
      adjusted = "unadjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))

unbal_spatial_road_bh_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb_spatial_road_bh(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    mutate(
      #campaign = row_number(),
      version = "business hours",
      design = "road type", 
      visits = "median 4",
      adjusted = "adjusted"
    ) %>%
    as.data.frame() %>% 
  mutate(dif = id - lag(id)) %>% 
  mutate(campaign = accumulate(dif[-1], .init = 1,
                            ~ if(.y < 0) {
                              .x + 1
                            } else {
                              .x
                            }))


unbal_spatial_road_bh_design = rbind(unbal_spatial_road_bh_unadj, unbal_spatial_road_bh_adj)

saveRDS(unbal_spatial_road_bh_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbal_spatial_road_bh.rds"))
```

 
```{r}
#combine spatial datasets

save_dir = "//projects/trap/transfer/annie/OnroadAnnAvgs"

PNC_spatial = unbal_cluster_design %>% 
  bind_rows(unbal_cluster_bh_design, 
            unbal_spatial_design, 
            unbal_spatial_design_bh,
            unbal_spatial2_design, 
            unbal_spatial2_bh_design, 
            unbal_spatial_road_design, 
            unbal_spatial_road_bh_design) %>% 
  select(-dif)

saveRDS(PNC_spatial, file=file.path(save_dir, "PNC_spatial_annavgs.rds"))


```



**OLD**  

## Design 1: Sample 6 or 12 number of visits per site

```{r}
#try for 1 campaign
# one_sample = unadj_pnc_med %>%
#   group_by(id, visit_num) %>% 
#   nest() %>%            
#   ungroup() %>% 
#   mutate(n = round(visit_num/2, 0)) %>%
#   mutate(samp = map2(data, n, sample_n)) %>% 
#   select(-data) %>%
#   unnest(samp) %>% 
#   group_by(id) %>% 
#   mutate(visits = n()) %>%
#     #calculate annual average
#   summarise(annual_mean = mean(median_value, na.rm=T))


one_sample_avg = function(df) {
  one_sample = df %>%
  group_by(id, visit_num) %>% 
  nest() %>%            
  ungroup() %>% 
  mutate(n = round(visit_num/2, 0)) %>%
  mutate(samp = map2(data, n, sample_n)) %>% 
  select(-data) %>%
  unnest(samp) %>% 
  group_by(id) %>% 
  mutate(visits = n()) %>%
    #calculate annual average
  summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample)
}
  



half_visits_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      adjusted = "unadjusted",
      design = "half visits"
    ) %>%
    as.data.frame()

half_visits_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      adjusted = "adjusted",
      design = "half visits"
    ) %>%
    as.data.frame()


half_visits = rbind(half_visits_unadj, half_visits_adj)

saveRDS(half_visits, file = file.path("TRAP_rotation", "data", "PNC_annavg_halfvisits.rds"))
  
```


## Unbalanced design 1  
Sample all segments, where the visits sampled is a skewed distribution, but same number within route  

```{r}
set.seed(21)
#visits=12
#create lognormal distribution of visits to sample from by route
#median for one is 12, for another is 6

#GM = median = 6; geometric SD = 2
visit_nums = rlnorm(50, log(6), log(2))
visit_nums = round(visit_nums, digits=0)

#try for 1 campaign
# one_sample = unadj_pnc_med %>%
#   mutate(route = substr(runname,12, 14)) %>% 
#   group_by(route) %>% 
#   mutate(weight = sample(visit_nums, 1)) %>% 
#   group_by(id, weight) %>%
#   nest() %>%
#   ungroup() %>%
#   mutate(samp = map2(data, weight, sample_n, replace=T)) %>%
#   select(-data) %>%
#   unnest(samp) %>%
#   group_by(id) %>%
#   mutate(visits = n()) %>%
#     #calculate annual average
#   summarise(annual_mean = mean(median_value, na.rm=T))

one_sample_avg_unb = function(df) {
  one_sample = df%>%
    mutate(route = substr(runname,12, 14)) %>% 
    group_by(route) %>% 
    mutate(weight = sample(visit_nums, 1)) %>% 
    group_by(id, weight) %>%
    nest() %>%
    ungroup() %>%
    mutate(samp = map2(data, weight, sample_n, replace=T)) %>%
    select(-data) %>%
    unnest(samp) %>%
    group_by(id) %>%
    mutate(visits = n()) %>%
      #calculate annual average
    summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample)
}


unbal_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      adjusted = "unadjusted",
      design = "skewed visits"
    ) %>%
    as.data.frame()

unbal_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      adjusted = "adjusted",
      design = "skewed visits"
    ) %>%
    as.data.frame()


unbal_design = rbind(unbal_unadj, unbal_adj)

saveRDS(unbal_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbalanced.rds"))
```


## Unbalanced design 2  
Sample all segments among only 4 routes, where the visits sampled is a skewed distribution, but same number within route 
4 routes: 1 (downtown); 4 (Airport and south); 7 (north/residential); 5 (bellevue)

```{r}

visits=12
#create skewed distribution of visits to sample from by route
visit_nums = c(1, 2,2,2,2,3,3,3,4,4,4,5,5,5,5,6,6,6,6,6,6,7,7,7,7,
               8,8,8,8,8,9,9,9,10,10,10,11,12,12,12,12,12,13,14,15, 
               15, 16,17, 17, 18, 19, 20)


one_sample_avg_unb2 = function(df) {
  one_sample = df%>%
    mutate(route = substr(runname,12, 14)) %>% 
    filter(route %in% c("R01", "R04", "R05", "R07")) %>% 
    group_by(route) %>% 
    mutate(weight = sample(visit_nums, 1)) %>% 
    group_by(id, weight) %>%
    nest() %>%
    ungroup() %>%
    mutate(samp = map2(data, weight, sample_n, replace=T)) %>%
    select(-data) %>%
    unnest(samp) %>%
    group_by(id) %>%
    mutate(visits = n()) %>%
      #calculate annual average
    summarise(annual_mean = mean(median_value, na.rm=T))
  
  return(one_sample)
}


unbal2_unadj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb2(unadj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      adjusted = "unadjusted",
      design = "skewed visits, spatially clustered"
    ) %>%
    as.data.frame()

unbal2_adj <- future_replicate(n = sim_n,
                           simplify = F,
                           expr = one_sample_avg_unb2(adj_pnc_med), 
                           mc.cores = 4, 
                           ) %>%
    bind_rows() %>%
    group_by(id) %>%
    mutate(
      campaign = row_number(),
      version = "all hours",
      adjusted = "adjusted",
      design = "skewed visits, spatially clustered"
    ) %>%
    as.data.frame()


unbal2_design = rbind(unbal2_unadj, unbal2_adj)

saveRDS(unbal2_design, file = file.path("TRAP_rotation", "data", "PNC_annavg_unbalanced_spatial.rds"))
```
