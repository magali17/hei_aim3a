---
title: "Untitled"
output: html_document
date: "2024-04-23"
editor_options: 
  chunk_output_type: console
---

# --> TO DO: SEARCH FOR 'TEMP/TO DO' (E.G., remove things that helped run code faster)

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = F, 
                      cache=F, cache.comments = F, 
                      message = F, warning = F, 
                      tidy.opts=list(width.cutoff=60), tidy=TRUE#, fig.height = 10, fig.width = 10
                      )  

# Clear workspace of all objects and unload all extra (non-base) packages
rm(list = ls(all = TRUE))
if (!is.null(sessionInfo()$otherPkgs)) {
  res <- suppressWarnings(
    lapply(paste('package:', names(sessionInfo()$otherPkgs), sep=""),
           detach, character.only=TRUE, unload=TRUE, force=TRUE))
}

pacman::p_load(tidyverse, lubridate, #zoo,
               kableExtra, ggpubr, #stat_cor()
               sf
               )    

source("functions.R")
dt_pt <- file.path("data", "onroad", "annie", "v2")
dt_pt2 <- file.path("data", "onroad", "annie", "v2", "temporal_adj", "20240421")
image_path <- file.path("..", "..", "Manuscript", "Images", "v4", "other", "road")
dt_out <- file.path("Output", readRDS(file.path("Output", "latest_dt_version.rda")), "qc", "road")
if(!dir.exists(dt_out)){dir.create(dt_out, recursive = T)}

set.seed(1)

# ggplot settings
theme_set(theme_bw())
theme_update(legend.position = "bottom")

##################################################################################################
# VARIABLES
##################################################################################################
main_road_types <-"no_highways" 
main_bg <- "hr3_pct1" #"hr1_pct5"
main_cluster <- "cluster1"

#lat/long
project_crs <- 4326  

# speed thigns up
testing_mode <- FALSE #e.g., reduce visit designs & windows/quantile combinations

##################################################################################################
# FUNCTIONS
##################################################################################################
# TEMP to reduce file sizes
make_dt_smaller <- function(dt) {
  dt %>%
    filter(!cluster_type %in% c("cluster2", "cluster3"),
           !design %in% c("unbalanced", "unsensible", "road_type"),
           background_adj == main_bg)
  }

```

# Load data 

```{r}
# adjusted annual averages (n=30 campaigns per design-version)
annual_adj2 <- readRDS(file.path(dt_pt2, "site_avgs_uw_adj.rds")) %>% 
  mutate(road_types = "all_road_types") %>%
  bind_rows(readRDS(file.path(dt_pt2, "site_avgs_uw_adj_no_hwy.rds")) %>% mutate(road_types = "no_highways"))  
  
# hourly adjustments
# #note that 'R00' routes have been combined b/c there were multiple 'routes' per day
underwrite_adj <- bind_rows(readRDS(file.path(dt_pt2, "underwrite_temp_adj.rda")) %>% mutate(road_types = "all_road_types"),
                            readRDS(file.path(dt_pt2, "underwrite_temp_adj_no_hwy.rda")) %>% mutate(road_types = "no_highways")) #%>%
  # --> TEMP
  #filter(background_adj == "hr1_pct5")
if(testing_mode==TRUE) {
  underwrite_adj <- underwrite_adj %>%
    filter(!grepl("pct10", background_adj))
}

# # adjusted visits [LARGE FILES!]
# visits_adj2 <- readRDS(file.path(dt_pt2, "bh_visits_fixed_site_temporal_adj_uw.rds")) %>%
#   mutate(date = as.Date(date)) 
# 
# visits_adj2_no_hwy <- readRDS(file.path(dt_pt2, "bh_visits_fixed_site_temporal_adj_uw_no_hwy.rds")) %>%
#   mutate(date = as.Date(date),
#          hour = as.numeri(hour))  
# 
# if(testing_mode==TRUE) {
#   visits_adj2 <- make_dt_smaller(visits_adj2)
#   visits_adj2_no_hwy <- make_dt_smaller(visits_adj2_no_hwy)
# }

# 1sec data with rolling quantiles
road_dt <- readRDS(file.path(dt_pt2, "underwrite_temp_adj_all_1s_data.rda")) %>% 
  mutate(road_types = "all_road_types")
road_dt_no_hwy <- readRDS(file.path(dt_pt2, "underwrite_temp_adj_all_1s_data_no_hwy.rda")) %>% 
  mutate(road_types = "no_highways")

if(testing_mode==TRUE) {
  road_dt <- filter(road_dt, !grepl("pct10", background_adj))
  road_dt_no_hwy <- filter(road_dt_no_hwy, !grepl("pct10", background_adj))
}

# segment lat/long/road type
segment_info <- readRDS(file.path(dt_pt, "segment_lat_long.rda")) %>%
  st_as_sf(coords=c("mx", "my"), crs=project_crs)

ltas <- distinct(underwrite_adj, background_adj, road_types, bg_lta)

bg_data <- ltas %>% 
    filter(road_types == main_road_types,
           background_adj %in% main_bg) %>%
    mutate(ufp = "background_lta")

```

# Data available

```{r}
# 1 sec
road_dt_no_hwy %>%
  filter(background_adj == main_bg,
         road_types == main_road_types) %>%  
  drop_na(ufp) %>%
  summarize(n_1sec_measurements = n()) %>%
  kable(caption = "Number of 1-sec UFP measures from the P-TRAK") %>%
  kable_styling()

# mean 1-sec measures per hour
road_dt_no_hwy %>%
  filter(background_adj == main_bg,
         road_types == main_road_types) %>%
  drop_na(ufp) %>%
  mutate(date=date(time),
         hour = hour(time)) %>%
  group_by(date, hour) %>%
  summarize(n=n()) %>%
  ungroup() %>%
  summarize(
    min = min(n),
    mean = mean(n),
    sd = sd(n),
    max=max(n)
  ) %>%
  kable(caption = "distribution of 1-sec measures per hour...these are NOT used to calculate hourly background b/c of how rolling quantiles are calcualted (they fill in data gaps)", 
        digits = 0) %>%
  kable_styling()


# mean 1-sec measures per hour
road_dt_no_hwy %>%
  filter(background_adj == main_bg,
         road_types == main_road_types) %>%
  drop_na(background) %>%
  mutate(date=date(time),
         hour = hour(time)) %>%
  group_by(date, hour) %>%
  summarize(n=n()) %>%
  ungroup() %>%
  summarize(
    min = min(n),
    mean = mean(n),
    sd = sd(n),
    max=max(n)
  ) %>%
  kable(caption = "distribution of 1-sec background estimates per hour...these are used to calculate background", 
        digits = 0) %>%
  kable_styling()



# number of hourly adjustments
underwrite_adj %>%
  filter(background_adj == main_bg,
         road_types == main_road_types) %>%
  summarize(n_hourly_adjustments = n()) %>%
  kable(caption = "Number of hourly PNC adjustments") %>%
  kable_styling()



```


# Temporal Adjustments

these are all very similar 
## hourly adjustments 

```{r}
###################################################################################################
# TEST
# # check that only 1 hourly adj per approach. looks good
# underwrite_adj %>%
#   filter(background_adj == main_bg,
#          road_types == main_road_types)  %>%
#   distinct(time, background_adj) %>%
#   group_by(time, background_adj) %>%
#   mutate(n=n()) %>% 
#   filter(n>1)

###################################################################################################

# time series: by background adj
underwrite_adj %>%
  #mutate(background_adj = factor(background_adj, levels=adj_lvls)) %>%
  
  ggplot(aes(x=time, y=avg_hourly_adj, col=background_adj, linetype=road_types)) + 
  #facet_wrap(~background_adj) +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +
  geom_point(alpha=0.3) + 
  geom_smooth() + 
  labs(y = "Adjustment (pt/cm3)",
       x = "Hour During the Study Period")

print("correlation between hwy & non-hwy approach by window/percentile")
underwrite_adj %>%
  select(-c(bg_hour_avg, bg_lta)) %>%
  pivot_wider(names_from = road_types, values_from = avg_hourly_adj) %>%
  group_by(background_adj) %>%
  summarize(r = cor(all_road_types, no_highways)) %>%
  kable(caption = "Pearson correlation (R) for temporal adjustments using all road types vs no highways readings. adjustments are almost identical.", digits = 4) %>%
  kable_styling()

#print(paste0("Comparison of hourly adjustments for the ", main_road_types, " approach"))
underwrite_adj %>%
  #filter(road_types == main_road_types) %>% 
  select(-c(bg_hour_avg, bg_lta)) %>%
  pivot_wider(names_from = background_adj, values_from = avg_hourly_adj) %>% 
  pivot_longer(cols = c(starts_with("hr"), -all_of(main_bg))) %>%
  
  # --> need to update 'hr1_pct5' if change this
  ggplot(aes(x=hr1_pct5, y=value, col=name)) + 
  facet_wrap(~road_types) +
  geom_point(alpha=0.3) + 
  geom_smooth() +
  geom_abline(slope = 1, intercept = 0, linetype=2, alpha=0.5) +
  stat_cor(method = "pearson", r.digits=5) + 
  labs(y = "Alternative background Adjustment",
       x = paste0("Main background adjustment (", main_bg, ")"))


 
#############
print("example of a few runs. results are similar")
#sample_runs
set.seed(1)
sample_runs <- underwrite_adj %>%
  group_by(runname) %>%
  mutate(hour_duration = length(unique(hour))) %>%
  ungroup() %>%
  filter(hour_duration>=5) %>%
  distinct(runname) %>% 
  slice_sample(n=6, replace=F) %>% pull()

print("estimated hourly background concentrations for various approaches. dashed lines are the LTAs from each approach")
underwrite_adj %>%
  filter(runname %in% sample_runs) %>%
  
  ggplot(aes(x=time, y=bg_hour_avg, col=background_adj, shape=road_types, linetype=road_types)) + 
  facet_wrap(~runname, scales="free_x") +
  geom_hline(data=ltas, aes(yintercept=bg_lta, col=background_adj, linetype=road_types), alpha=0.5) +
  geom_point() + 
  geom_line() +
  labs(x = "Time",
       y = "Hourly Background Conc (pt/cm3)",
       col = "Background Adjustment",
       linetype = "Roads Used", shape = "Roads Used")

#ggsave(file.path(dt_out, "example_bg_conc.png"), width = 14, height = 8)

print("same as above but hourly adjustments vs estimated background concentrations")
underwrite_adj %>%
  filter(runname %in% sample_runs) %>%
  
  ggplot(aes(x=time, y=avg_hourly_adj, col=background_adj, shape=road_types, linetype=road_types)) + 
  facet_wrap(~runname, scales="free_x") +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +
  geom_point() + 
  geom_line() + 
  labs(x = "Time",
       y = "Hourly Adjustment (pt/cm3)",
       col = "Background Adjustment",
       linetype = "Roads Used", shape = "Roads Used")

#ggsave(file.path(dt_out, "example_hourly_adjustments.png"), width = 14, height = 8)

##################################################################################################
# by DOW
print(paste0("Distribution of hourly adjustments for ", main_road_types, " approach by DOW"))
underwrite_adj %>%
  # filter(#background_adj == main_bg,
  #        road_types == main_road_types
  #        ) %>%
  mutate(dow = wday(date, label=T, week_start = "Monday")) %>%
  ggplot(aes(x=dow, y=avg_hourly_adj, fill= interaction(background_adj, road_types), #fill=road_types
             )) +
  #facet_wrap(~road_types) +
  geom_boxplot() +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +
  labs(y = "Hourly Adjustment",
       x = "Day",
       fill = "Adjustment Approach")

#ggsave(file.path(dt_out, "temp_adj2_dow.png"), width = 14, height = 8)

##################################################################################################
# by hour
print(paste0("Distribution of hourly adjustments for ", main_road_types, " approach by hour"))
underwrite_adj %>%
  #filter(road_types == main_road_types) %>%
  mutate(hour = factor(hour, levels=c(1:23, 0))) %>%
  ggplot(aes(x=hour, y=avg_hourly_adj, fill=interaction(road_types, background_adj))) +
  #facet_wrap(~road_types) +
  geom_boxplot() +
  geom_hline(yintercept = 0, linetype=2, alpha=0.5) +
  labs(title = paste0("Distribution of hourly adjustments for ", main_road_types, " approach"),
       y = "Hourly Adjustment",
       x = "Hour",
       fill = "Adjustment Approach")

```

## 1-second time series of adjustments

```{r}
##################################################################################################
# time series fn
time_series_plot <- function(runs) {
  all <- filter(road_dt, runname %in% runs)
  no_highways <- filter(road_dt_no_hwy, runname %in% runs)
  
  bg_data <- ltas %>% 
    filter(background_adj %in% main_bg) %>%
    mutate(ufp = "background_lta")
  
  bind_rows(all, no_highways) %>% 
    # only show main approach
    filter(background_adj %in% main_bg) %>%
    
    rename(measured_ufp=ufp, background_ufp_1s = background) %>%
    mutate(hour = hour(time)) %>%
    left_join(select(underwrite_adj, runname, hour, background_adj, road_types, background_ufp_1hr = bg_hour_avg), relationship="many-to-many") %>%
    pivot_longer(cols = c(measured_ufp, background_ufp_1s, background_ufp_1hr), names_to = "ufp") %>% 
    
    ggplot(aes(x=time, col=ufp, linetype=road_types)) +
    facet_grid(background_adj~runname, scales="free_x", switch = "both") +
    geom_line(aes(y=value)) +
    geom_hline(data=bg_data, aes(yintercept=bg_lta,  col=ufp, linetype=road_types)) + 
    labs(y="UFP (pt/cm3)",
         x="Time"
    )
  }

# time_series_plot(sample_ts_runs) + scale_y_log10()

##################################################################################################

# TIME SERIES: ONROAD MEASURES VS 'BACKGROUND' (E.G., Brantley Fig 5)
 
print("you see: some segments/time periods are lower than the estimated background; background estimates are available even when no UFP measures are available so long as some measures are available for a given window (e.g., 1+ measurement in 1 hr)")

print("2020-02-26_R01 is an example of how negative annual averages might arise? all readings were above normal, so 'background' ufp is higher & also get some very low readings...when u adjust UFP readings, this could result in very low/negative readings. if no other readings are collected, you end up with a negative annual average.")

set.seed(1) #seed 1 has good example of a day when most readings are below & above the LTA
sample_ts_runs <- sample(unique(underwrite_adj$runname), 2)
time_series_plot(sample_ts_runs) 

print("on log y scale")
time_series_plot(sample_ts_runs) + scale_y_log10()

#ggsave(file.path(dt_out, "time_series_sample.png"), width = 12, height = 8)
```

## visits vs hourly adjustments (FILES ARE TOO LARGE)


```{r, eval=F}
# --> add time series plot of visits vs hourly adjustments (like above) 
# visit_dt= visits_adj2_no_hwy
# runs = sample_ts_runs

vists_vs_adjustments_plot <- function(visit_dt, runs) {
  runnames <- distinct(underwrite_adj, runname, date, hour) %>%
    filter(runname %in% runs)
  
  dt <- filter(visit_dt,
               background_adj == main_bg) %>% 
    right_join(runnames) 
  
  dt %>%
    select(date, hour, id, adjusted, median_value, avg_hourly_adj, median_value_adjusted) %>%  
    pivot_longer(cols = c(median_value, avg_hourly_adj, median_value_adjusted), names_to = "ufp") %>% View()
    
 
    
    ggplot(aes(x=time, col=ufp, linetype=road_types)) +
    facet_grid(background_adj~runname, scales="free_x", switch = "both") +
    geom_line(aes(y=value)) +
    geom_hline(data=bg_data, aes(yintercept=bg_lta,  col=ufp, linetype=road_types)) + 
    labs(y="UFP (pt/cm3)",
         x="Time"
    )
}


##################################################################################################
# --> ?add example of ~1 wk period
# --> LS: consider overlaying same route driven on same time…driving same structure






```

## Maps - Temporal adjustment over space 

```{r}
print("road segments by road type")
segment_info %>%
  ggplot(aes(col=road_type)) + 
  geom_sf()


```


```{r}
# --> maps to make sure background doesn't vary by space (e.g., near vs away from hwys). use 1sec rolling quantiles?

#1 sec data
temp0 <-  road_dt %>%
  bind_rows(road_dt_no_hwy) %>%
  #filter(background_adj == main_bg) %>%
  left_join(segment_info, by="id") %>% 
  drop_na(road_type) 

# annual avg road segment conc
temp <- road_dt %>%
  bind_rows(road_dt_no_hwy) %>%
  group_by(id, background_adj, road_types) %>%
  summarize(background_sd = sd(background, na.rm = T),
            background = mean(background, na.rm = T),
            ufp = mean(ufp, na.rm = T)) %>%
  ungroup %>%
  #filter(background_adj == main_bg) %>%
  left_join(segment_info, by="id") %>%
  mutate(background_adj = factor(background_adj, levels=unique(.$background_adj) %>% as.character() %>% sort())) %>%
  drop_na(mx, my)


#print("1-second background UFP is slightly higher on A1s")
 
temp0 %>%
#temp %>%
  filter(background_adj == main_bg) %>%
  ggplot(aes(x=road_type, y=background, #fill= background_adj
             fill=road_types
             )) + 
  facet_wrap(~background_adj) +
  geom_boxplot() + 
  labs(#y = "Annual average background PNC per road segment",
       y = "1-sec background PNC by road type"
       )


print("see higher 'background' concentrations near I-5")
temp %>% 
  st_as_sf(coords = c("mx", "my"), crs=project_crs) %>%
  ggplot(aes(col=background)) + 
  facet_grid(road_types~background_adj, switch="y") +
  geom_sf(size=0.8) +
  scale_color_viridis_b() + 
  labs(col = "Annual Avg Background UFP (pt/cm3)")

temp %>% 
  st_as_sf(coords = c("mx", "my"), crs=project_crs) %>%
  ggplot(aes(col=background_sd)) + 
  facet_grid(road_types~background_adj, switch="y") +
  geom_sf(size=0.8) +
  scale_color_viridis_b() + 
  labs(col = "SD of 1-sec 'Background' UFP (pt/cm3)")



```




# Annual averages

annual averages are almost identical when temporal adjustments w/ and w/o measurements from highways are used to develop temporal adjsutment factors 

```{r}
print("Annual averages by adjustment approach for each location-design-campaign for. annual averages are not plume adjusted & the main cluster approach")

# correlation table
print("temporally-adjsuted annual averages are almost identical")
temp <- annual_adj2 %>%
  filter((is.na(cluster_type) | cluster_type == main_cluster),
          
         #adjusted == "unadjusted"
         ) %>%
  pivot_wider(names_from = background_adj, values_from = annual_mean) %>% 
  pivot_longer(cols = c(starts_with("hr"), -all_of(main_bg))) 

paste0("correlations of annual average segment PNCs between the main  (", main_bg, ") and alternative background approachs") 
temp %>%
  group_by(road_types, adjusted, name) %>%
  summarize(
    n=n(),
    correlation = cor(get(main_bg), value)) %>%
  ggplot(aes(x=name, y=correlation, col=road_types, shape=adjusted)) + 
  geom_point(size=2) + 
  labs(y="Correlation (R) of Annual Averages After Temporal Adjustment",
       x = "Background Adjustment Approach"
       )
  
   
 

#plot
annual_adj2 %>%
  ggplot(aes(x=road_types, y=annual_mean, fill=background_adj)) +  #adjusted
  #facet_wrap(~road_types) + 
  geom_boxplot() + 
  labs(y = "segment annual average from various backround adjustment approaches"
  )


```

## Negative Annual averages


```{r}
 
# since annual averages are very similar, we'll look at main analyses here 
annual_adj2_main <- annual_adj2 %>%
  # since all are similar, focus onthe main analysis
  filter(background_adj == main_bg,
         (is.na(cluster_type) | cluster_type == main_cluster),
         road_types == main_road_types) 

##################################################################################################
annual_avg_by_visits_plot <- function(dt) {
  #set.seed(1)
  dt %>%
    #slice_sample(n=.1*nrow(.), ) %>%
    mutate(actual_visits = factor(actual_visits),
           visits = paste0("median ", visits, " per location")) %>%
    group_by(visits, actual_visits) %>%
    mutate(no_annual_avgs=n()) %>%
    
    ggplot(aes(x=actual_visits, y=annual_mean,col=adjusted #col=  #design  #cluster_type #background_adj
    )) + 
    facet_wrap(~background_adj+road_types #~design+background_adj
               ) +
    geom_hline(yintercept = 0, linetype=2, col="red") +
    #geom_hline(yintercept = 1e3, linetype=2) +
    geom_boxplot() +
    labs(x = "Actual Visits per Location",
         y = "Estimated Site Annual Average",
         col = "Plume", fill = "Plume")
   }
##################################################################################################
# more liely to have negative, more variable site averages results when collect few visits
# and for plume adjusted approaches that slightly reduce concentrations
# more common w/ 4 visit designs b/c there are more total annual averages on the low end (more common to only have 1 visit)

print("distribution of estimated annual averages after background adjustments during BH following various clustering & non-clustered sampling approahces (collapses plume adjusted & unadjusted)")
print("dashed black line is at 1e3")

annual_adj2_main %>%
  annual_avg_by_visits_plot()

#ggsave(file.path(dt_out, "annual_conc_vs_visit_num.png"), width = 14, height = 8)

```

```{r}
annual_adj2_main %>%
  mutate(negative_conc = ifelse(annual_mean<=0, "negative annual avg", "positive annual avg")) %>% 
  group_by(negative_conc) %>%  
  summarize(n =n(),
            precent = n/nrow(annual_adj2_main)*100
            ) %>%
  kable(caption = "a tiny proportion of segments end up with negative annual averages (across campaigns-design, adjusted...)") %>%
  kable_styling()

```

```{r, eval=F}
# F, has_visit data - visits_adj2_no_hwy

# --> what are the sites with negative annual averages? sites with large negative hourly adjustments & low visit concentrations?
print("negative annual averages happen when the hourly adjustment is very negative (observed values were higher than the LTA during that hour) & a specific segment concentration (e.g., the median from few seconds of measurements) is lower. sampling with replacement may additionally resample the same site")
negative_sites <- annual_adj2_main %>%
  filter(annual_mean<=0) %>% 
  
  # --> visit data is large 
  left_join(visits_adj2_no_hwy, relationship = "one-to-many")

negative_sites %>%
  ggplot(aes(x=median_value, 
             y=median_value_adjusted,
             #y=avg_hourly_adj, 
             col=time)) + 
  geom_hline(yintercept = 0, linetype=3, alpha=0.5, col="red") +
  #geom_vline(xintercept = 0, linetype=3, alpha=0.5, col="red") +
  geom_point() + 
  geom_smooth() +
  geom_abline(slope = 1, intercept = 0, linetype=2, alpha=0.5)
  

# date-hour combinations that lead to negative annual averages later on. are these extreme? 
negative_sites %>%
  mutate(avg_hourly_adj = round(avg_hourly_adj)) %>%
  ggplot(aes(y=date, x=hour, #fill=avg_hourly_adj, group=avg_hourly_adj
             )) + 
  geom_bin_2d(#stat="identity"
              ) + 
  geom_text(aes(label=avg_hourly_adj), col="green")
  
```

# Visits

# --> anything to do here??

```{r}

```

